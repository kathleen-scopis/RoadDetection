{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import zipfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract zip file quickly and in gitignore'd folder\n",
    "\n",
    "zip_file_path = \"./data/archive.zip\"\n",
    "\n",
    "# Step 2: Extract the downloaded zip file\n",
    "extracted_folder_path = \"./data/RoadDetectionFiles\"\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extracted_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "\n",
    "test_image = './data/RoadDetectionFiles/Test/image/'\n",
    "train_image = './data/RoadDetectionFiles/Train/image/'\n",
    "validation_image = './data/RoadDetectionFiles/Validation/image/'\n",
    "\n",
    "test_centerline = './data/RoadDetectionFiles/Test/centerline/'\n",
    "train_centerline = './data/RoadDetectionFiles/Train/centerline/'\n",
    "validation_centerline = './data/RoadDetectionFiles/Validation/centerline/'\n",
    "\n",
    "test_label = './data/RoadDetectionFiles/Test/label/'\n",
    "train_label = './data/RoadDetectionFiles/Train/label/'\n",
    "validation_label = './data/RoadDetectionFiles/Validation/label/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "options we are ditching\n",
    "- find pretrained unet (too hard)\n",
    "- train a unet for semantic segmentation (takes too much time)\n",
    "\n",
    "\n",
    "option we are doing:\n",
    "- resize label images to be all same size - same size as image\n",
    "- make a disclaimer that 44 photos is very few\n",
    "- calculate the sum score for each image - number of pixels classified as a road\n",
    "- Train a CNN network to predict number of road pixels (similar to HW3 , but the output is a single score)\n",
    "\n",
    "\n",
    "- extension: instead of using regular images, crop patches to like 100x100 images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to crop all images to be the same size - since the images are all different aspect ratios, the images need to be cropped, not just resized\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def crop_to_square(image_path, output_path, dimension):\n",
    "    # Open the image\n",
    "    with Image.open(image_path) as img:\n",
    "        \n",
    "        # Calculate crop box coordinates\n",
    "        left = (img.width - dimension) / 2\n",
    "        top = (img.height - dimension) / 2\n",
    "        right = (img.width + dimension) / 2\n",
    "        bottom = (img.height + dimension) / 2\n",
    "\n",
    "        # Crop the image to the square\n",
    "        cropped_img = img.crop((left, top, right, bottom))\n",
    "\n",
    "        # Save the cropped image\n",
    "        cropped_img.save(output_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494\n",
      "494\n",
      "411\n",
      "411\n",
      "572\n",
      "572\n",
      "the dimension to crop all images to is 411 x 411\n"
     ]
    }
   ],
   "source": [
    "# find the largest square that can fit inside all the images - this will be the dimensions to crop the image\n",
    "\n",
    "def find_crop_dim(folder):\n",
    "    max_dimension = 10000 # placeholder\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.bmp'):\n",
    "            input_path = os.path.join(folder, filename)\n",
    "            # img = Image.open(input_path)\n",
    "            with Image.open(input_path) as img:\n",
    "                max_dimension = min(max_dimension, min(img.width, img.height))\n",
    "    return max_dimension\n",
    "\n",
    "# the label images are extracted from the satellite images, so it makes sense they are the same dimension\n",
    "\n",
    "print(find_crop_dim(train_image))\n",
    "print(find_crop_dim(train_label))\n",
    "print(find_crop_dim(validation_image))\n",
    "print(find_crop_dim(validation_label))\n",
    "print(find_crop_dim(test_image))\n",
    "print(find_crop_dim(test_label))\n",
    "\n",
    "# the largest possible bounding box is a crop of the smallest square for all images in the entire train, test and validation\n",
    "dim = min(find_crop_dim(train_image),find_crop_dim(validation_image),find_crop_dim(test_image))\n",
    "print(\"the dimension to crop all images to is\",dim,\"x\",dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop the images using the dimensions found!\n",
    "\n",
    "def run_crop(input_folder, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Loop through images in the input folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith('.bmp'):\n",
    "            input_path = os.path.join(input_folder, filename)\n",
    "            output_path = os.path.join(output_folder, filename)\n",
    "            crop_to_square(input_path, output_path, dim)\n",
    "\n",
    "run_crop(train_image,'./data/RoadDetectionFilesCropped/Train/image/')\n",
    "run_crop(train_label,'./data/RoadDetectionFilesCropped/Train/label/')\n",
    "run_crop(validation_image,'./data/RoadDetectionFilesCropped/Validation/image/')\n",
    "run_crop(validation_label,'./data/RoadDetectionFilesCropped/Validation/label/')\n",
    "run_crop(test_image,'./data/RoadDetectionFilesCropped/Test/image/')\n",
    "run_crop(test_image,'./data/RoadDetectionFilesCropped/Test/label/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save filepaths to cropped folders\n",
    "\n",
    "train_image_crop = './data/RoadDetectionFilesCropped/Train/image/'\n",
    "train_label_crop = './data/RoadDetectionFilesCropped/Train/label/'\n",
    "validation_image_crop = './data/RoadDetectionFilesCropped/Validation/image/'\n",
    "validation_label_crop = './data/RoadDetectionFilesCropped/Validation/label/'\n",
    "test_image_crop = './data/RoadDetectionFilesCropped/Test/image/'\n",
    "test_image_crop = './data/RoadDetectionFilesCropped/Test/label/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set order of data layers to match requirements for cnn\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, dim, dim)\n",
    "else:\n",
    "    input_shape = (dim, dim, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sofia\\mambaforge\\envs\\musa-550-fall-2023\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "# create layers for CNN model process\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "m6 = Sequential()\n",
    "m6.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "m6.add(Activation('relu'))\n",
    "m6.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "m6.add(Conv2D(32, (3, 3)))\n",
    "m6.add(Activation('relu'))\n",
    "m6.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "m6.add(Conv2D(64, (3, 3)))\n",
    "m6.add(Activation('relu'))\n",
    "m6.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "m6.add(Flatten())\n",
    "m6.add(Dense(64))\n",
    "m6.add(Activation('relu'))\n",
    "m6.add(Dropout(0.5))\n",
    "m6.add(Dense(1))\n",
    "m6.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "musa-550-fall-2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
