{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import zipfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract zip file quickly and in gitignore'd folder\n",
    "\n",
    "zip_file_path = \"./data/archive.zip\"\n",
    "\n",
    "# Step 2: Extract the downloaded zip file\n",
    "extracted_folder_path = \"./data/RoadDetectionFiles\"\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extracted_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "\n",
    "test_image = './data/RoadDetectionFiles/Test/image'\n",
    "train_image = './data/RoadDetectionFiles/Train/image'\n",
    "validation_image = './data/RoadDetectionFiles/Validation/image'\n",
    "\n",
    "test_centerline = './data/RoadDetectionFiles/Test/centerline'\n",
    "train_centerline = './data/RoadDetectionFiles/Train/centerline'\n",
    "validation_centerline = './data/RoadDetectionFiles/Validation/centerline'\n",
    "\n",
    "test_label = './data/RoadDetectionFiles/Test/label'\n",
    "train_label = './data/RoadDetectionFiles/Train/label'\n",
    "validation_label = './data/RoadDetectionFiles/Validation/label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat gpt code to design a CasNet architecture to simultaneously handle road detection and centerline extraction tasks\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define directories\n",
    "train_image_dir = './data/RoadDetectionFiles/Train/image'\n",
    "validation_image_dir = './data/RoadDetectionFiles/Validation/image'\n",
    "test_image_dir = './data/RoadDetectionFiles/Test/image'\n",
    "\n",
    "train_centerline_dir = './data/RoadDetectionFiles/Train/centerline'\n",
    "validation_centerline_dir = './data/RoadDetectionFiles/Validation/centerline'\n",
    "test_centerline_dir = './data/RoadDetectionFiles/Test/centerline'\n",
    "\n",
    "# Image dimensions\n",
    "image_height = 128\n",
    "image_width = 128\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "\n",
    "# Load the data\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_image_generator = train_datagen.flow_from_directory(\n",
    "        train_image_dir,\n",
    "        target_size=(image_height, image_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,  # No class labels\n",
    "        color_mode='grayscale')  # Assuming grayscale images\n",
    "\n",
    "train_centerline_generator = train_datagen.flow_from_directory(\n",
    "        train_centerline_dir,\n",
    "        target_size=(image_height, image_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,  # No class labels\n",
    "        color_mode='grayscale')  # Assuming grayscale images\n",
    "\n",
    "validation_image_generator = validation_datagen.flow_from_directory(\n",
    "        validation_image_dir,\n",
    "        target_size=(image_height, image_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,  # No class labels\n",
    "        color_mode='grayscale')  # Assuming grayscale images\n",
    "\n",
    "validation_centerline_generator = validation_datagen.flow_from_directory(\n",
    "        validation_centerline_dir,\n",
    "        target_size=(image_height, image_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,  # No class labels\n",
    "        color_mode='grayscale')  # Assuming grayscale images\n",
    "\n",
    "test_image_generator = test_datagen.flow_from_directory(\n",
    "        test_image_dir,\n",
    "        target_size=(image_height, image_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,  # No class labels\n",
    "        color_mode='grayscale')  # Assuming grayscale images\n",
    "\n",
    "test_centerline_generator = test_datagen.flow_from_directory(\n",
    "        test_centerline_dir,\n",
    "        target_size=(image_height, image_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,  # No class labels\n",
    "        color_mode='grayscale')  # Assuming grayscale images\n",
    "\n",
    "# Combine image and centerline generators into one\n",
    "train_generator = zip(train_image_generator, train_centerline_generator)\n",
    "validation_generator = zip(validation_image_generator, validation_centerline_generator)\n",
    "test_generator = zip(test_image_generator, test_centerline_generator)\n",
    "\n",
    "# Define CasNet architecture\n",
    "input_img = layers.Input(shape=(image_height, image_width, 1))\n",
    "\n",
    "# Road Detection Branch\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "road_output = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same', name='road_output')(x)\n",
    "\n",
    "# Centerline Extraction Branch\n",
    "y = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "y = layers.MaxPooling2D((2, 2), padding='same')(y)\n",
    "y = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(y)\n",
    "y = layers.MaxPooling2D((2, 2), padding='same')(y)\n",
    "y = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(y)\n",
    "centerline_output = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same', name='centerline_output')(y)\n",
    "\n",
    "# Combine both branches\n",
    "combined_output = layers.Concatenate()([road_output, centerline_output])\n",
    "\n",
    "model = models.Model(inputs=input_img, outputs=combined_output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'road_output': 'binary_crossentropy', 'centerline_output': 'binary_crossentropy'},\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "      train_generator,\n",
    "      epochs=num_epochs,\n",
    "      steps_per_epoch=len(train_image_generator),  # Adjust steps per epoch based on your data size\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=len(validation_image_generator))  # Adjust validation steps based on your data size\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=2, steps=len(test_image_generator))  # Adjust steps based on your data size\n",
    "print('\\nTest accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat gpt prompted code to do the same thing but this time U-Net\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define directories\n",
    "train_image_dir = './data/RoadDetectionFiles/Train/image'\n",
    "validation_image_dir = './data/RoadDetectionFiles/Validation/image'\n",
    "test_image_dir = './data/RoadDetectionFiles/Test/image'\n",
    "\n",
    "train_centerline_dir = './data/RoadDetectionFiles/Train/centerline'\n",
    "validation_centerline_dir = './data/RoadDetectionFiles/Validation/centerline'\n",
    "test_centerline_dir = './data/RoadDetectionFiles/Test/centerline'\n",
    "\n",
    "# Image dimensions\n",
    "image_height = 128\n",
    "image_width = 128\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "\n",
    "# Load the data\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_image_generator = train_datagen.flow_from_directory(\n",
    "        train_image_dir,\n",
    "        target_size=(image_height, image_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,  # No class labels\n",
    "        color_mode='grayscale')  # Assuming grayscale images\n",
    "\n",
    "train_centerline_generator = train_datagen.flow_from_directory(\n",
    "        train_centerline_dir,\n",
    "        target_size=(image_height, image_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,  # No class labels\n",
    "        color_mode='grayscale')  # Assuming grayscale images\n",
    "\n",
    "validation_image_generator = validation_datagen.flow_from_directory(\n",
    "        validation_image_dir,\n",
    "        target_size=(image_height, image_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,  # No class labels\n",
    "        color_mode='grayscale')  # Assuming grayscale images\n",
    "\n",
    "validation_centerline_generator = validation_datagen.flow_from_directory(\n",
    "        validation_centerline_dir,\n",
    "        target_size=(image_height, image_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,  # No class labels\n",
    "        color_mode='grayscale')  # Assuming grayscale images\n",
    "\n",
    "test_image_generator = test_datagen.flow_from_directory(\n",
    "        test_image_dir,\n",
    "        target_size=(image_height, image_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,  # No class labels\n",
    "        color_mode='grayscale')  # Assuming grayscale images\n",
    "\n",
    "test_centerline_generator = test_datagen.flow_from_directory(\n",
    "        test_centerline_dir,\n",
    "        target_size=(image_height, image_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,  # No class labels\n",
    "        color_mode='grayscale')  # Assuming grayscale images\n",
    "\n",
    "# Combine image and centerline generators into one\n",
    "train_generator = zip(train_image_generator, train_centerline_generator)\n",
    "validation_generator = zip(validation_image_generator, validation_centerline_generator)\n",
    "test_generator = zip(test_image_generator, test_centerline_generator)\n",
    "\n",
    "# Define U-Net architecture\n",
    "def unet(input_size=(image_height, image_width, 1)):\n",
    "    inputs = layers.Input(input_size)\n",
    "    \n",
    "    # Encoder\n",
    "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
    "    pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = layers.Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
    "    conv4 = layers.Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
    "    drop4 = layers.Dropout(0.5)(conv4)\n",
    "    pool4 = layers.MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = layers.Conv2D(1024, 3, activation='relu', padding='same')(pool4)\n",
    "    conv5 = layers.Conv2D(1024, 3, activation='relu', padding='same')(conv5)\n",
    "    drop5 = layers.Dropout(0.5)(conv5)\n",
    "\n",
    "    # Decoder\n",
    "    up6 = layers.Conv2D(512, 2, activation='relu', padding='same')(layers.UpSampling2D(size=(2, 2))(drop5))\n",
    "    merge6 = layers.concatenate([drop4, up6], axis=3)\n",
    "    conv6 = layers.Conv2D(512, 3, activation='relu', padding='same')(merge6)\n",
    "    conv6 = layers.Conv2D(512, 3, activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = layers.Conv2D(256, 2, activation='relu', padding='same')(layers.UpSampling2D(size=(2, 2))(conv6))\n",
    "    merge7 = layers.concatenate([conv3, up7], axis=3)\n",
    "    conv7 = layers.Conv2D(256, 3, activation='relu', padding='same')(merge7)\n",
    "    conv7 = layers.Conv2D(256, 3, activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = layers.Conv2D(128, 2, activation='relu', padding='same')(layers.UpSampling2D(size=(2, 2))(conv7))\n",
    "    merge8 = layers.concatenate([conv2, up8], axis=3)\n",
    "    conv8 = layers.Conv2D(128, 3, activation='relu', padding='same')(merge8)\n",
    "    conv8 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = layers.Conv2D(64, 2, activation='relu', padding='same')(layers.UpSampling2D(size=(2, 2))(conv8))\n",
    "    merge9 = layers.concatenate([conv1, up9], axis=3)\n",
    "    conv9 = layers.Conv2D(64, 3, activation='relu', padding='same')(merge9)\n",
    "    conv9 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv9)\n",
    "\n",
    "    # Output layers\n",
    "    road_output = layers.Conv2D(1, (1, 1), activation='sigmoid', name='road_output')(conv9)\n",
    "    centerline_output = layers.Conv2D(1, (1, 1), activation='sigmoid', name='centerline_output')(conv9)\n",
    "\n",
    "    model = models.Model(inputs=[inputs], outputs=[road_output, centerline_output])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create U-Net model\n",
    "model = unet()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'road_output': 'binary_crossentropy', 'centerline_output': 'binary_crossentropy'},\n",
    "              metrics={'road_output': 'accuracy', 'centerline_output': 'accuracy'})\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "      train_generator,\n",
    "      epochs=num_epochs,\n",
    "      steps_per_epoch=len(train_image_generator),  # Adjust steps per epoch based on your data size\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=len(validation_image_generator))  # Adjust validation steps based on your data size\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, road_test_loss, centerline_test_loss, road_test_acc, centerline_test_acc = model.evaluate(test_generator, verbose=2, steps=len(test_image_generator))  # Adjust steps based on your data size\n",
    "print('\\nTest Road Detection Accuracy:', road_test_acc)\n",
    "print('Test Centerline Extraction Accuracy:', centerline_test_acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "musa-550-fall-2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
