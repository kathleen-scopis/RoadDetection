{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import zipfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract zip file quickly and in gitignore'd folder\n",
    "\n",
    "zip_file_path = \"./data/archive.zip\"\n",
    "\n",
    "# Step 2: Extract the downloaded zip file\n",
    "extracted_folder_path = \"./data/RoadDetectionFiles\"\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extracted_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "\n",
    "test_image = './data/RoadDetectionFiles/Test/image/'\n",
    "train_image = './data/RoadDetectionFiles/Train/image/'\n",
    "validation_image = './data/RoadDetectionFiles/Validation/image/'\n",
    "\n",
    "test_centerline = './data/RoadDetectionFiles/Test/centerline/'\n",
    "train_centerline = './data/RoadDetectionFiles/Train/centerline/'\n",
    "validation_centerline = './data/RoadDetectionFiles/Validation/centerline/'\n",
    "\n",
    "test_label = './data/RoadDetectionFiles/Test/label/'\n",
    "train_label = './data/RoadDetectionFiles/Train/label/'\n",
    "validation_label = './data/RoadDetectionFiles/Validation/label/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "options we are ditching\n",
    "- find pretrained unet (too hard)\n",
    "- train a unet for semantic segmentation (takes too much time)\n",
    "\n",
    "\n",
    "option we are doing:\n",
    "- resize label images to be all same size - same size as image\n",
    "- make a disclaimer that 44 photos is very few\n",
    "- calculate the sum score for each image - number of pixels classified as a road\n",
    "- Train a CNN network to predict number of road pixels (similar to HW3 , but the output is a single score)\n",
    "\n",
    "\n",
    "- extension: instead of using regular images, crop patches to like 100x100 images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to crop all images to be the same size - since the images are all different aspect ratios, the images need to be cropped, not just resized\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def crop_to_square(image_path, output_path, dimension):\n",
    "    # Open the image\n",
    "    with Image.open(image_path) as img:\n",
    "        \n",
    "        # Calculate crop box coordinates\n",
    "        left = (img.width - dimension) / 2\n",
    "        top = (img.height - dimension) / 2\n",
    "        right = (img.width + dimension) / 2\n",
    "        bottom = (img.height + dimension) / 2\n",
    "\n",
    "        # Crop the image to the square\n",
    "        cropped_img = img.crop((left, top, right, bottom))\n",
    "\n",
    "        # Save the cropped image\n",
    "        cropped_img.save(output_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494\n",
      "494\n",
      "411\n",
      "411\n",
      "572\n",
      "572\n",
      "the dimension to crop all images to is 411 x 411\n"
     ]
    }
   ],
   "source": [
    "# find the largest square that can fit inside all the images - this will be the dimensions to crop the image\n",
    "\n",
    "def find_crop_dim(folder):\n",
    "    max_dimension = 10000 # placeholder\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.bmp'):\n",
    "            input_path = os.path.join(folder, filename)\n",
    "            # img = Image.open(input_path)\n",
    "            with Image.open(input_path) as img:\n",
    "                max_dimension = min(max_dimension, min(img.width, img.height))\n",
    "    return max_dimension\n",
    "\n",
    "# the label images are extracted from the satellite images, so it makes sense they are the same dimension\n",
    "\n",
    "print(find_crop_dim(train_image))\n",
    "print(find_crop_dim(train_label))\n",
    "print(find_crop_dim(validation_image))\n",
    "print(find_crop_dim(validation_label))\n",
    "print(find_crop_dim(test_image))\n",
    "print(find_crop_dim(test_label))\n",
    "\n",
    "# the largest possible bounding box is a crop of the smallest square for all images in the entire train, test and validation\n",
    "dim = min(find_crop_dim(train_image),find_crop_dim(validation_image),find_crop_dim(test_image))\n",
    "print(\"the dimension to crop all images to is\",dim,\"x\",dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop the images using the dimensions found!\n",
    "\n",
    "def run_crop(input_folder, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Loop through images in the input folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith('.bmp'):\n",
    "            input_path = os.path.join(input_folder, filename)\n",
    "            output_path = os.path.join(output_folder, filename)\n",
    "            crop_to_square(input_path, output_path, dim)\n",
    "\n",
    "run_crop(train_image,'./data/RoadDetectionFilesCropped/Train/image/')\n",
    "run_crop(train_label,'./data/RoadDetectionFilesCropped/Train/label/')\n",
    "run_crop(validation_image,'./data/RoadDetectionFilesCropped/Validation/image/')\n",
    "run_crop(validation_label,'./data/RoadDetectionFilesCropped/Validation/label/')\n",
    "run_crop(test_image,'./data/RoadDetectionFilesCropped/Test/image/')\n",
    "run_crop(test_image,'./data/RoadDetectionFilesCropped/Test/label/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save filepaths to cropped folders\n",
    "\n",
    "train_image_crop = './data/RoadDetectionFilesCropped/Train/image/'\n",
    "train_label_crop = './data/RoadDetectionFilesCropped/Train/label/'\n",
    "validation_image_crop = './data/RoadDetectionFilesCropped/Validation/image/'\n",
    "validation_label_crop = './data/RoadDetectionFilesCropped/Validation/label/'\n",
    "test_image_crop = './data/RoadDetectionFilesCropped/Test/image/'\n",
    "test_label_crop = './data/RoadDetectionFilesCropped/Test/label/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set order of data layers to match requirements for cnn\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, dim, dim)\n",
    "else:\n",
    "    input_shape = (dim, dim, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sofia\\mambaforge\\envs\\musa-550-fall-2023\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "# create layers for CNN model process - adapted from a model created in Homework 3\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "m6 = Sequential()\n",
    "m6.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "m6.add(Activation('relu'))\n",
    "m6.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "m6.add(Conv2D(32, (3, 3)))\n",
    "m6.add(Activation('relu'))\n",
    "m6.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "m6.add(Conv2D(64, (3, 3)))\n",
    "m6.add(Activation('relu'))\n",
    "m6.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "m6.add(Flatten())\n",
    "m6.add(Dense(64))\n",
    "m6.add(Activation('relu'))\n",
    "m6.add(Dropout(0.5))\n",
    "m6.add(Dense(1))\n",
    "m6.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model will be trained for regression because we are trying to predict a singular numeric outcome for each image, for the number of pixels that are roads\n",
    "\n",
    "# Compile the model for regression\n",
    "m6.compile(loss='mean_squared_error',\n",
    "           optimizer='rmsprop',\n",
    "           metrics=['mean_squared_error']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a set of functions that create a dataset of numeric values associated with the number of pixels belonging to roads for each satellite image\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Function to count road pixels in a labeled image\n",
    "def count_road_pixels(image_path):\n",
    "    # Load the image\n",
    "    image = Image.open(image_path)\n",
    "    # Convert the image to a numpy array\n",
    "    image_array = np.array(image)\n",
    "    # Count the number of road pixels (assuming roads are labeled as 1, adjust as needed)\n",
    "    num_road_pixels = np.sum(image_array == 1)\n",
    "    return num_road_pixels\n",
    "\n",
    "# simple function to just load in data\n",
    "def load_satellite_image(image_path):\n",
    "    # Load the image using PIL\n",
    "    image = Image.open(image_path)\n",
    "    # Optionally, perform preprocessing steps here (e.g., resizing, normalization)\n",
    "    return image\n",
    "\n",
    "# function to create dataset that appends road pixels to satellite images\n",
    "def create_model_dataset(labeled_images, satellite_images):\n",
    "# Create the dataset\n",
    "    dataset = []\n",
    "\n",
    "    for labeled_image_path, satellite_image_path in zip(labeled_images, satellite_images):\n",
    "        # Count the number of road pixels in the labeled image\n",
    "        num_road_pixels = count_road_pixels(labeled_image_path)\n",
    "        # Load the corresponding satellite image\n",
    "        satellite_image = load_satellite_image(satellite_image_path)  # You need to implement this function\n",
    "        # Append the satellite image and the number of road pixels to the dataset\n",
    "        dataset.append((satellite_image, num_road_pixels))\n",
    "    \n",
    "    return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '.'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# create the datasets to pass through the model for training and testing\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# train_label_crop = 'C:/Users/sofia/Documents/GitHub/RoadDetection/data/RoadDetectionFilesCropped/Train/label/'\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m \n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Call create_model_dataset function with absolute paths\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_model_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_label_crop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_image_crop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m test_data \u001b[38;5;241m=\u001b[39m create_model_dataset(test_label_crop, test_image_crop)\n",
      "Cell \u001b[1;32mIn[44], line 30\u001b[0m, in \u001b[0;36mcreate_model_dataset\u001b[1;34m(labeled_images, satellite_images)\u001b[0m\n\u001b[0;32m     26\u001b[0m dataset \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m labeled_image_path, satellite_image_path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(labeled_images, satellite_images):\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;66;03m# Count the number of road pixels in the labeled image\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m     num_road_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mcount_road_pixels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabeled_image_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;66;03m# Load the corresponding satellite image\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     satellite_image \u001b[38;5;241m=\u001b[39m load_satellite_image(satellite_image_path)  \u001b[38;5;66;03m# You need to implement this function\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[44], line 9\u001b[0m, in \u001b[0;36mcount_road_pixels\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcount_road_pixels\u001b[39m(image_path):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Load the image\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# Convert the image to a numpy array\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     image_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(image)\n",
      "File \u001b[1;32mc:\\Users\\sofia\\mambaforge\\envs\\musa-550-fall-2023\\lib\\site-packages\\PIL\\Image.py:3218\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3215\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[0;32m   3217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3218\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3219\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3221\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '.'"
     ]
    }
   ],
   "source": [
    "# create the datasets to pass through the model for training and testing\n",
    "\n",
    "# train_label_crop = 'C:/Users/sofia/Documents/GitHub/RoadDetection/data/RoadDetectionFilesCropped/Train/label/'\n",
    "# train_image_crop = 'C:/Users/sofia/Documents/GitHub/RoadDetection/data/RoadDetectionFilesCropped/Train/image/'\n",
    "# test_label_crop = 'C:/Users/sofia/Documents/GitHub/RoadDetection/data/RoadDetectionFilesCropped/Test/label/'\n",
    "# test_image_crop = 'C:/Users/sofia/Documents/GitHub/RoadDetection/data/RoadDetectionFilesCropped/Test/image/'\n",
    "\n",
    "# Call create_model_dataset function with absolute paths\n",
    "train_data = create_model_dataset(train_label_crop, train_image_crop)\n",
    "test_data = create_model_dataset(test_label_crop, test_image_crop)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "musa-550-fall-2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
