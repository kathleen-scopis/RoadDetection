{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import zipfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract zip file quickly and in gitignore'd folder\n",
    "\n",
    "zip_file_path = \"./data/archive.zip\"\n",
    "\n",
    "# Step 2: Extract the downloaded zip file\n",
    "extracted_folder_path = \"./data/RoadDetectionFiles\"\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extracted_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "\n",
    "test_image = './data/RoadDetectionFiles/Test/image/'\n",
    "train_image = './data/RoadDetectionFiles/Train/image/'\n",
    "validation_image = './data/RoadDetectionFiles/Validation/image/'\n",
    "\n",
    "test_centerline = './data/RoadDetectionFiles/Test/centerline/'\n",
    "train_centerline = './data/RoadDetectionFiles/Train/centerline/'\n",
    "validation_centerline = './data/RoadDetectionFiles/Validation/centerline/'\n",
    "\n",
    "test_label = './data/RoadDetectionFiles/Test/label/'\n",
    "train_label = './data/RoadDetectionFiles/Train/label/'\n",
    "validation_label = './data/RoadDetectionFiles/Validation/label/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "options we are ditching\n",
    "- find pretrained unet (too hard)\n",
    "- train a unet for semantic segmentation (takes too much time)\n",
    "\n",
    "\n",
    "option we are doing:\n",
    "- resize label images to be all same size - same size as image\n",
    "- make a disclaimer that 44 photos is very few\n",
    "- calculate the sum score for each image - number of pixels classified as a road\n",
    "- Train a CNN network to predict number of road pixels (similar to HW3 , but the output is a single score)\n",
    "\n",
    "\n",
    "- extension: instead of using regular images, crop patches to like 100x100 images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to crop all images to be the same size - since the images are all different aspect ratios, the images need to be cropped, not just resized\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def crop_to_square(image_path, output_path, dimension):\n",
    "    # Open the image\n",
    "    with Image.open(image_path) as img:\n",
    "        \n",
    "        # Calculate crop box coordinates\n",
    "        left = (img.width - dimension) / 2\n",
    "        top = (img.height - dimension) / 2\n",
    "        right = (img.width + dimension) / 2\n",
    "        bottom = (img.height + dimension) / 2\n",
    "\n",
    "        # Crop the image to the square\n",
    "        cropped_img = img.crop((left, top, right, bottom))\n",
    "\n",
    "        # Save the cropped image\n",
    "        cropped_img.save(output_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494\n",
      "494\n",
      "411\n",
      "411\n",
      "572\n",
      "572\n",
      "the dimension to crop all images to is 411 x 411\n"
     ]
    }
   ],
   "source": [
    "# find the largest square that can fit inside all the images - this will be the dimensions to crop the image\n",
    "\n",
    "def find_crop_dim(folder):\n",
    "    max_dimension = 10000 # placeholder\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.bmp'):\n",
    "            input_path = os.path.join(folder, filename)\n",
    "            # img = Image.open(input_path)\n",
    "            with Image.open(input_path) as img:\n",
    "                max_dimension = min(max_dimension, min(img.width, img.height))\n",
    "    return max_dimension\n",
    "\n",
    "# the label images are extracted from the satellite images, so it makes sense they are the same dimension\n",
    "\n",
    "print(find_crop_dim(train_image))\n",
    "print(find_crop_dim(train_label))\n",
    "print(find_crop_dim(validation_image))\n",
    "print(find_crop_dim(validation_label))\n",
    "print(find_crop_dim(test_image))\n",
    "print(find_crop_dim(test_label))\n",
    "\n",
    "# the largest possible bounding box is a crop of the smallest square for all images in the entire train, test and validation\n",
    "dim = min(find_crop_dim(train_image),find_crop_dim(validation_image),find_crop_dim(test_image))\n",
    "print(\"the dimension to crop all images to is\",dim,\"x\",dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop the images using the dimensions found!\n",
    "\n",
    "def run_crop(input_folder, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Loop through images in the input folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith('.bmp'):\n",
    "            input_path = os.path.join(input_folder, filename)\n",
    "            output_path = os.path.join(output_folder, filename)\n",
    "            crop_to_square(input_path, output_path, dim)\n",
    "\n",
    "run_crop(train_image,'./data/RoadDetectionFilesCropped/Train/image/')\n",
    "run_crop(train_label,'./data/RoadDetectionFilesCropped/Train/label/')\n",
    "run_crop(validation_image,'./data/RoadDetectionFilesCropped/Validation/image/')\n",
    "run_crop(validation_label,'./data/RoadDetectionFilesCropped/Validation/label/')\n",
    "run_crop(test_image,'./data/RoadDetectionFilesCropped/Test/image/')\n",
    "run_crop(test_image,'./data/RoadDetectionFilesCropped/Test/label/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save filepaths to cropped folders\n",
    "\n",
    "train_image_crop = './data/RoadDetectionFilesCropped/Train/image/'\n",
    "train_label_crop = './data/RoadDetectionFilesCropped/Train/label/'\n",
    "validation_image_crop = './data/RoadDetectionFilesCropped/Validation/image/'\n",
    "validation_label_crop = './data/RoadDetectionFilesCropped/Validation/label/'\n",
    "test_image_crop = './data/RoadDetectionFilesCropped/Test/image/'\n",
    "test_label_crop = './data/RoadDetectionFilesCropped/Test/label/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set order of data layers to match requirements for cnn\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, dim, dim)\n",
    "else:\n",
    "    input_shape = (dim, dim, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sofia\\mambaforge\\envs\\musa-550-fall-2023\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "# create layers for CNN model process - adapted from a model created in Homework 3\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "m6 = Sequential()\n",
    "input_shape = (dim, dim, 3)  # Define your image dimensions and number of channels\n",
    "m6.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "m6.add(Activation('relu'))\n",
    "m6.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "m6.add(Conv2D(32, (3, 3)))\n",
    "m6.add(Activation('relu'))\n",
    "m6.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "m6.add(Conv2D(64, (3, 3)))\n",
    "m6.add(Activation('relu'))\n",
    "m6.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "m6.add(Flatten())\n",
    "m6.add(Dense(64))\n",
    "m6.add(Activation('relu'))\n",
    "m6.add(Dropout(0.5))\n",
    "m6.add(Dense(1))\n",
    "m6.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model will be trained for regression because we are trying to predict a singular numeric outcome for each image, for the number of pixels that are roads\n",
    "\n",
    "# Compile the model for regression\n",
    "m6.compile(loss='mean_squared_error',\n",
    "           optimizer='rmsprop',\n",
    "           metrics=['mean_squared_error']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create a dataset that combines the satellite imagery with the number of pixels belonging to roads calculated from the label. Tis will train the model\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "\n",
    "def create_model_dataset(label_directory, image_directory):\n",
    "    # Initialize the dataset\n",
    "    dataset = []\n",
    "\n",
    "    # Loop through files in the label directory\n",
    "    for label_filename in os.listdir(label_directory):\n",
    "        # Extract numeric part of the filename\n",
    "        match = re.match(r'(\\d+)', label_filename)\n",
    "        if match:\n",
    "            base_filename = match.group(1)\n",
    "        else:\n",
    "            continue  # Skip this file if no numeric part is found\n",
    "\n",
    "        # Construct corresponding image filename\n",
    "        image_filename = 'image' + base_filename + '.bmp'\n",
    "\n",
    "        # Load label image and calculate number of road pixels\n",
    "        label_image = Image.open(os.path.join(label_directory, label_filename))\n",
    "        label_array = np.array(label_image)\n",
    "        num_road_pixels = np.sum(label_array == 1)\n",
    "\n",
    "        # Load satellite image\n",
    "        satellite_image = Image.open(os.path.join(image_directory, image_filename))\n",
    "\n",
    "        # Append to the dataset\n",
    "        dataset.append((num_road_pixels, satellite_image))\n",
    "\n",
    "    # Now you have the dataset ready for training\n",
    "    return dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the datasets to pass through the model for training and testing\n",
    "\n",
    "train_label_crop = './data/RoadDetectionFilesCropped/Train/label'\n",
    "train_image_crop = './data/RoadDetectionFilesCropped/Train/image'\n",
    "test_label_crop = './data/RoadDetectionFilesCropped/Test/label'\n",
    "test_image_crop = './data/RoadDetectionFilesCropped/Test/image'\n",
    "\n",
    "# Call create_model_dataset function with absolute paths\n",
    "train_data = create_model_dataset(train_label_crop, train_image_crop)\n",
    "test_data = create_model_dataset(test_label_crop, test_image_crop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ImageDataGenerator' from 'keras.preprocessing.image' (c:\\Users\\sofia\\mambaforge\\envs\\musa-550-fall-2023\\lib\\site-packages\\keras\\preprocessing\\image\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageDataGenerator\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Assuming train_data is your list of tuples containing (num_road_pixels, satellite_image)\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'ImageDataGenerator' from 'keras.preprocessing.image' (c:\\Users\\sofia\\mambaforge\\envs\\musa-550-fall-2023\\lib\\site-packages\\keras\\preprocessing\\image\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "# Assuming train_data is your list of tuples containing (num_road_pixels, satellite_image)\n",
    "train_data = train_data # Your training dataset\n",
    "\n",
    "# Convert the list of tuples to separate lists for pixels and images\n",
    "pixels, images = zip(*train_data)\n",
    "pixels = np.array(pixels)  # Convert to numpy array\n",
    "images = np.array(images)  # Convert to numpy array\n",
    "\n",
    "# Create an instance of ImageDataGenerator with any desired preprocessing options\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,  # You can add more preprocessing options if needed\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# Create a generator for training data\n",
    "train_generator = train_datagen.flow(\n",
    "    x=images,\n",
    "    y=pixels,\n",
    "    batch_size=32,\n",
    "    shuffle=True)  # Shuffle the data\n",
    "\n",
    "# Now you can use train_generator to generate batches of data during model training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming m6 is your compiled CNN model\n",
    "\n",
    "# Train the model using fit_generator\n",
    "history = m6.fit_generator(\n",
    "    generator=train_generator,\n",
    "    steps_per_epoch=len(train_data) // 32,\n",
    "    epochs=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "musa-550-fall-2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
